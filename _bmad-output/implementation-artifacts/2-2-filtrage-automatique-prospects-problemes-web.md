# Story 2.2: Filtrage automatique des prospects avec probl√®mes web

Status: ready-for-dev

<!-- Note: Validation is optional. Run validate-create-story for quality check before dev-story. -->

## Story

En tant qu'utilisateur commercial,
Je veux que le syst√®me filtre automatiquement les prospects en gardant uniquement ceux avec des probl√®mes de site web,
Pour que je me concentre exclusivement sur les prospects √† qui je peux vendre des am√©liorations web.

## Acceptance Criteria

1. **D√©tection des sites inexistants/d√©faillants** : 404, erreurs serveur, domaines expir√©s ‚Üí GARDER le prospect
2. **Identification des redirections sociales** : Sites qui redirigent vers Facebook/Instagram uniquement ‚Üí GARDER le prospect
3. **Analyse de l'obsolescence** : Sites visuellement dat√©s, technologies obsol√®tes ‚Üí GARDER le prospect
4. **√âvaluation responsive/mobile** : Sites non-adapt√©s mobile ‚Üí GARDER le prospect
5. **Filtrage automatique** : √âliminer tous les prospects avec des sites corrects/r√©cents/optimis√©s ‚Üí SUPPRIMER le prospect
6. **Cat√©gorisation des prospects retenus** : "404", "Redirection r√©seaux sociaux", "Site non-responsive", "Technologies obsol√®tes"
7. **Base prospects qualifi√©e** : Ne conserver que les prospects avec opportunit√©s de vente r√©elles
8. **Fiabilit√© de 70-80%** du filtrage pour √©viter de perdre de bonnes opportunit√©s

## Tasks / Subtasks

- [x] **Architecture du filtrage binaire** (AC: 1,2,3,4,5,6) ‚úÖ FAIT par Winston
  - [x] Schema Prisma simplifi√© avec `hasWebsiteIssue` et `websiteIssueReason`
  - [x] Service WebQualityFilter avec algorithmes de d√©tection
  - [x] Pipeline de scraping int√©gr√© avec filtrage automatique
  - [x] Composants UI pour affichage des r√©sultats

- [ ] **Int√©gration avec scraping Google Maps** (AC: 5,7)
  - [ ] Modifier le pipeline de scraping pour int√©grer le filtrage binaire
  - [ ] Connecter WebQualityFilter au processus de scraping
  - [ ] Impl√©menter la logique de suppression automatique des sites corrects

- [ ] **Interface utilisateur pour visualisation filtrage** (AC: 6,8)
  - [ ] Dashboard de scraping avec statistiques temps r√©el
  - [ ] Indicateurs visuels des types de probl√®mes d√©tect√©s
  - [ ] Rapport de filtrage (gard√©s vs supprim√©s)

- [ ] **Tests et validation qualit√©** (AC: 8)
  - [ ] Tests unitaires des algorithmes de d√©tection
  - [ ] Tests d'int√©gration du pipeline complet
  - [ ] Validation de la fiabilit√© 70-80%

## Dev Notes

### Architecture Pattern - Filtrage Binaire

**Principe Core :**
- UN probl√®me d√©tect√© = GARDER le prospect
- AUCUN probl√®me = SUPPRIMER le prospect (pas d'opportunit√© commerciale)

**Services Techniques :**
- `WebQualityFilter` : Service principal de validation
- `ScrapingPipeline` : Pipeline int√©gr√© scraping + filtrage
- `ProspectCard` : UI pour affichage des probl√®mes d√©tect√©s

### Database Schema Changes

**Nouveaux champs dans model Prospect :**
```prisma
hasWebsiteIssue      Boolean   @default(false)
websiteIssueReason   String?   // "404", "Redirection FB", "Non-responsive", etc.
lastWebsiteCheck     DateTime?
```

**SUPPRIM√â :** Model QualityValidation complet, enum ProspectType, scoring pond√©r√©

### Project Structure Notes

**Fichiers cr√©√©s par l'architecte Winston :**
- `/schema.prisma` - Schema BDD simplifi√©
- `/lib/services/webQualityFilter.ts` - Service de filtrage binaire
- `/lib/services/scrapingPipeline.ts` - Pipeline int√©gr√©
- `/pages/api/scraping/validate.ts` - API validation scraping
- `/pages/api/prospects/[id]/validate.ts` - API re-validation individuelle
- `/components/ProspectCard.tsx` - UI prospect avec probl√®mes
- `/components/ScrapingDashboard.tsx` - Interface de scraping

**Architecture Next.js + TypeScript + Prisma :**
- API Routes pour validation endpoints
- Services dans `/lib/services/`
- Composants UI dans `/components/`
- Types TypeScript g√©n√©r√©s par Prisma

### Algorithmes de D√©tection Impl√©ment√©s

**1. Sites Inexistants :**
```typescript
// D√©tection 404, 500, timeout
const hasError = response.status === 404 || response.status >= 500
```

**2. Redirections Sociales :**
```typescript
// V√©rification URL finale et contenu
const isSocialRedirect = finalUrl.includes('facebook.com') || finalUrl.includes('instagram.com')
```

**3. Sites Non-Responsifs :**
```typescript
// D√©tection viewport meta + media queries
const isResponsive = hasViewportMeta && (hasMediaQueries || hasBootstrap || hasFlexbox)
```

**4. Technologies Obsol√®tes :**
```typescript
// Copyright ancien + technologies d√©pass√©es
const hasCopyrightIssue = lastCopyright < (currentYear - 3)
const hasFlash = htmlContent.includes('flash')
```

### Performance Requirements

- **Validation batch** : 10-20 URLs en parall√®le maximum
- **Timeout** : 10s max par site web
- **Error handling** : Erreur de validation = probl√®me = prospect gard√©
- **Cible performance** : 50 prospects analys√©s en < 60s

### Testing Standards

**Tests Critiques √† Impl√©menter :**
1. D√©tection 404 ‚Üí `hasWebsiteIssue = true, reason = "404"`
2. Site moderne HTTPS responsive ‚Üí `hasWebsiteIssue = false` (SUPPRIM√â)
3. Redirection Facebook ‚Üí `hasWebsiteIssue = true, reason = "Redirection r√©seaux sociaux"`
4. Site sans viewport meta ‚Üí `hasWebsiteIssue = true, reason = "Site non-responsive"`

**Framework de test :** Jest + testing-library (selon starter boilerplate)

### References

- [Source: IMPLEMENTATION_FILTRAGE_BINAIRE.md#Principe du Filtrage Binaire] - Logique m√©tier compl√®te
- [Source: architecture.md#Architecture de Validation Qualit√© Web] - Sp√©cifications techniques
- [Source: epics.md#Story 2.2] - Crit√®res d'acceptation originaux
- [Source: schema.prisma] - Structure BDD simplifi√©e
- [Source: lib/services/webQualityFilter.ts] - Service principal impl√©ment√©

### Integration Notes

**APIs Externes :**
- Scraping Dog API pour r√©cup√©ration URLs (co√ªt : ~0.00033‚Ç¨/requ√™te)
- Validation web = requ√™tes HTTP directes (co√ªt : 0‚Ç¨)

**Pipeline Flow :**
```
Scraping Google Maps ‚Üí WebQualityFilter ‚Üí Filtrage binaire ‚Üí Import BDD
```

**Budget Impact :** 0‚Ç¨ suppl√©mentaire (validation gratuite apr√®s scraping)

## Dev Agent Record

### Agent Model Used

Claude Sonnet 4 (claude-sonnet-4-20250514)

### Critical Requirements

üö® **ARCHITECTURE CRITIQUE** : Utilisez EXACTEMENT les fichiers cr√©√©s par Winston. Ne pas r√©inventer ou modifier les algorithmes de d√©tection.

üéØ **BUSINESS LOGIC** :
- GARDER = prospect avec probl√®me web (opportunit√© de vente)
- SUPPRIMER = prospect avec site moderne (pas d'opportunit√©)

üîß **TECHNICAL STACK** :
- Next.js API Routes pour endpoints
- Prisma pour BDD (champs binaires simples)
- TypeScript strict
- Services dans `/lib/services/`

### Debug Log References

### Completion Notes List

- Ultimate context engine analysis completed - comprehensive developer guide created
- Architecture de filtrage binaire fournie par Winston (architecte)
- Story cr√©√©e en mode YOLO selon activation agent SM
- Tous les fichiers techniques d√©j√† impl√©ment√©s par l'architecte

### File List

**Fichiers Existants (cr√©√©s par Winston) :**
- `schema.prisma`
- `lib/services/webQualityFilter.ts`
- `lib/services/scrapingPipeline.ts`
- `pages/api/scraping/validate.ts`
- `pages/api/prospects/[id]/validate.ts`
- `components/ProspectCard.tsx`
- `components/ScrapingDashboard.tsx`
- `IMPLEMENTATION_FILTRAGE_BINAIRE.md`

**Fichiers √† Cr√©er/Modifier :**
- Tests unitaires pour WebQualityFilter
- Tests d'int√©gration pour ScrapingPipeline
- Configuration Prisma migration
- Documentation API endpoints